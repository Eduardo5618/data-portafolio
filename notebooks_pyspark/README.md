# Notebooks de Pr치ctica con PySpark

Este m칩dulo forma parte de mi portafolio de datos y contiene notebooks pr치cticos desarrollados con PySpark, enfocados en tareas comunes de ingenier칤a de datos: lectura de archivos, limpieza, joins, agregaciones y manipulaci칩n de fechas a gran escala.

Los ejemplos est치n pensados para correr en modo local y utilizar datasets ficticios que simulan escenarios reales en entornos de negocio.

---

## 游닂 Temario

| Notebook                           | Descripci칩n                                                                 |
|------------------------------------|-----------------------------------------------------------------------------|
| `01_spark_basico.ipynb`            | Configuraci칩n de Spark, lectura de CSVs, filtros y transformaciones simples |
| `02_transformaciones_avanzadas.ipynb` | `withColumn`, `when`, limpieza de strings, renombrar y conversi칩n de tipos |
| `03_joins_y_ventanas.ipynb`        | Joins (`inner`, `left`), `row_number()`, `lag()`, `lead()`, `partitionBy`  |
| `04_aggregations_pivot_fechas.ipynb`| `groupBy`, agregaciones, `pivot()`, manejo y truncado de fechas            |

---

## 游빓 Tecnolog칤as usadas

- Apache Spark 3.x
- PySpark
- Python 3.9+
- Jupyter Notebooks

> 游눠 Todos los notebooks est치n comentados y pueden ejecutarse en local usando datasets de prueba incluidos en la carpeta `datasets/`.
